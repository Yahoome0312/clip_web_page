<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1.2 Weak Supervision - CLIP</title>
    <link rel="stylesheet" href="../assets/styles/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\\\[', right: '\\\\]', display: true}
        ]
    });"></script>
</head>
<body>

    <header>
        <nav>
            <div class="logo">CLIP</div>
            <div class="nav-links">
                <a href="../index.html">Home</a>
                <a href="section1-1.html" class="active">1. Background</a>
                <a href="section2-1.html">2. Methodology</a>
                <a href="section3-1.html">3. Applications</a>
                <a href="section4.html">4. Conclusion</a>
            </div>
        </nav>
    </header>

    <main>
        <h1>1. Background</h1>
        
        <div class="chapter-nav">
            <a href="section1-1.html">1.1 Supervised Learning</a>
            <a href="section1-2.html" class="active-chapter">1.2 Weak Supervision</a>
            <a href="section1-3.html">1.3 CLIP Core Idea</a>
        </div>

        <section class="content-section">
            <h2>1.2 Weak Supervision and the Generative Trap</h2>
            <p>
                Researchers have long realized that manually labeling datasets is unscalable. 
                However, the internet is full of <strong>natural signals</strong>: HTML alt text, social media captions, and news descriptions.
                Leveraging this data is known as <span class="term-highlight">Natural Language Supervision<span class="term-tooltip">Training models on pairs of images and text found naturally on the web.</span></span>.
            </p>

            <div style="background: #ffffff; padding: 1.5rem; border-radius: 8px; margin: 2rem 0; border-left: 4px solid var(--secondary-color); border: 1px solid #e2e8f0; border-left-width: 4px;">
                <h3>The "Old Way": Generative Objectives (VirTex, ICMLM)</h3>
                <p>
                    Prior models tried to <strong>generate</strong> the text caption from the image pixel-by-pixel.
                </p>
                <div style="font-family: monospace; background: #f1f5f9; padding: 1rem; border-radius: 6px; margin-top: 1rem; color: #334155; border: 1px solid #cbd5e1;">
                    Input: [Image] &rarr; Prediction: "A" &rarr; "cute" &rarr; "puppy" ...
                </div>
            </div>

            <h3>The Flaw: High Entropy & The Generative Trap</h3>
            <p>
                While appealing, this strategy fails because image descriptions have <strong>High Entropy</strong> (high uncertainty).
            </p>

            <div style="display: flex; gap: 2rem; align-items: flex-start; margin-top: 2rem; flex-wrap: wrap;">
                <div style="flex: 1; min-width: 250px; text-align: center;">
                    <img src="../assets/images/dog.jpg" alt="A dog" style="width: 100%; max-width: 300px; border-radius: 8px; border: 2px solid #e2e8f0;">
                    <p style="font-size: 0.8rem; color: #64748b; margin-top: 0.5rem;">One Image, Infinite Captions</p>
                </div>
                
                <div style="flex: 1; min-width: 300px;">
                    <div style="background: #ffffff; padding: 1.5rem; border-radius: 8px; border: 1px solid #e2e8f0;">
                        <h4 style="color: #ef4444; margin-bottom: 1rem;">Why is predicting text hard?</h4>
                        <p>A single image can be correctly described in many ways. If the model predicts one valid caption but the dataset has another, it gets penalized.</p>
                        <ul style="list-style: none; padding: 0; margin-top: 1rem;">
                            <li style="padding: 0.5rem; border-bottom: 1px solid #f1f5f9; color: #10b981;">✔ "A cute puppy"</li>
                            <li style="padding: 0.5rem; border-bottom: 1px solid #f1f5f9; color: #10b981;">✔ "My pet Fido"</li>
                            <li style="padding: 0.5rem; border-bottom: 1px solid #f1f5f9; color: #10b981;">✔ "An animal on the grass"</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <h3 style="margin-top: 2rem;">Computational Inefficiency</h3>
            <p>
                Forcing a model to predict every single word wastes computation on non-visual words like "a", "the", "is". 
                <strong>CLIP's insight:</strong> We don't need to generate the text. We just need to understand if it matches.
            </p>
        </section>

        <div class="page-nav">
            <a href="section1-1.html" class="btn btn-secondary">&larr; Previous</a>
            <a href="section1-3.html" class="btn">Next: 1.3 CLIP Core Idea &rarr;</a>
        </div>

    </main>
</body>
</html>