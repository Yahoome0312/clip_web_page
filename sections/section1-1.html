<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1.1 Rigid Standard Supervised Learning - CLIP</title>
    <link rel="stylesheet" href="../assets/styles/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
    });"></script>
</head>
<body>

    <header>
        <nav>
            <div class="logo">CLIP</div>
            <div class="nav-links">
                <a href="../index.html">Home</a>
                <a href="section1-1.html" class="active">1. Background</a>
                <a href="section2-1.html">2. Methodology</a>
                <a href="section3.html">3. Applications</a>
                <a href="section4.html">4. Conclusion</a>
            </div>
        </nav>
    </header>

    <main>
        <h1>1. Background</h1>
        
        <div class="chapter-nav">
            <a href="section1-1.html" class="active-chapter">1.1 Supervised Learning</a>
            <a href="section1-2.html">1.2 Weak Supervision</a>
            <a href="section1-3.html">1.3 CLIP Core Idea</a>
        </div>

        <section class="content-section">
            <h2>1.1 Standard Supervised Learning</h2>
            <p>
                Before Clip, progress in computer vision was driven by a single dominant paradigm: <strong>Standard Supervised Learning</strong>. 
                Models like ResNet, VGG, and AlexNet were trained to answer one specific question:
            </p>
            <blockquote style="border-left: 4px solid var(--primary-color); padding-left: 1rem; margin: 1.5rem 0; font-style: italic; color: #475569;">
                "Which of these $N$ predefined categories does this image belong to?"
            </blockquote>
            
            <p>
                The workflow follows a strict formula:
                $$ \text{Input Image} \rightarrow \text{Extract Features} \rightarrow \text{Predict Fixed Class Label} $$
            </p>

            <h3>The Closed World Assumption</h3>
            <p>
                This paradigm operates in a "closed world". It assumes a fixed label set (ontology) and a fixed decision head. Once trained, the model's vocabulary is frozen.
                If a model is trained on ImageNet (which has 1,000 classes), its entire universe consists of only those 1,000 concepts.
            </p>

            <div class="visual-container" style="flex-direction: column; gap: 1rem; background: #f8fafc; border: 1px solid #e2e8f0;">
                <h4 style="color: var(--secondary-color);">Visualization: The Fixed Vocabulary Problem</h4>
                <div style="display: flex; align-items: center; gap: 1rem; flex-wrap: wrap; justify-content: center; width: 100%;">
                    
                    <!-- Input -->
                    <div style="text-align: center;">
                        <img src="../assets/images/dog.jpg" alt="Dog" style="width: 120px; height: 120px; object-fit: cover; border: 2px solid #cbd5e1; border-radius: 8px;">
                    </div>

                    <div style="font-size: 2rem; color: #94a3b8;">&rarr;</div>

                    <!-- Model -->
                    <div style="padding: 1rem; background: #e2e8f0; border-radius: 8px; color: #1e293b;">
                        <strong>Deep CNN</strong><br>
                        (ResNet-50)
                    </div>

                    <div style="font-size: 2rem; color: #94a3b8;">&rarr;</div>

                    <!-- Output Head -->
                    <div style="display: flex; flex-direction: column; gap: 0.5rem; background: #ffffff; padding: 1rem; border-radius: 8px; border: 2px solid #cbd5e1;">
                        <div style="color: #64748b;">Class 1: Goldfish</div>
                        <div style="color: #64748b;">...</div>
                        <div style="color: var(--secondary-color); font-weight: bold;">Class 254: Pug</div>
                        <div style="color: #64748b;">...</div>
                        <div style="color: #64748b;">Class 1000: Toilet Tissue</div>
                    </div>
                </div>
                <p class="placeholder-text" style="font-size: 0.9rem; margin-top: -0.6rem; margin-bottom: -0.6rem; color: #ef4444; text-align: center;">
                    What if we show it a "Pikachu"? <br>
                    It forces a prediction into one of the 1,000 existing classes (e.g., "Yellow Balloon")<br>
                    Obiviously, it is wrong.
                </p>
            </div>

            <h3>The Core Flaw: Ontological Rigidity</h3>
            <p>This approach suffers from a fundamental limitation called <span class="term-highlight">Ontological Rigidity<span class="term-tooltip">The inability of a system to adapt its knowledge structure (ontology) to new concepts without re-training.</span></span>.</p>
            
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin-top: 1.5rem;">
                <div class="card" style="background: rgba(255,255,255,0.05); padding: 1rem; border-radius: 8px;">
                    <h4 style="color: var(--accent-color);">1. Fixed Vocabulary</h4>
                    <p style="font-size: 0.95rem;">
                        The model can only recognize concepts it was explicitly taught. <br>
                         If a model is trained on ImageNet, it cannot recognize "Pikachu," "COVID-19 Face Masks," or a "Tesla Cybertruck," because these categories simply do not exist in the indices.
                    </p>
                </div>
                <div class="card" style="background: rgba(255,255,255,0.05); padding: 1rem; border-radius: 8px;">
                    <h4 style="color: var(--accent-color);">2. Loss of Semantics</h4>
                    <p style="font-size: 0.95rem;">
                        To the model, Class <em>Dalmatian</em> (label 10) and Class <em>German Shepherd</em> (label 15) are just orthogonal indices in a One-Hot vector: $[0, ..., 1, ..., 0]$.
                        <br>The mathematical distance between <em>these two dog breeds</em> is the same as the distance between a <em>"Dog"</em> and a <em>"Taxicab"</em>, which loses the semantic hierarchy that exists in the real world.
                    </p>
                </div>
            </div>

            <div style="margin-top: 2rem; padding: 1.5rem; background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-left: 4px solid var(--primary-color); border-radius: 8px;">
                <h4 style="color: var(--primary-color); margin-bottom: 0.75rem; font-size: 1.1rem;">This rigidity is <strong>not a bug</strong></h4>
                <p style="margin-bottom: 0.5rem; font-size: 1rem;">
                    <I>It is a direct consequence of the <strong>classification objective</strong>.
                </p>
                <p style="font-size: 0.95rem; color: #475569; margin: 0;">
                    ðŸ’¡ To fix this, we need a way to learn from data that evolves naturally, without predefined labels.
                </p>
            </div>
        </section>

        <div class="page-nav">
            <a href="../index.html" class="btn btn-secondary">&larr; Home</a>
            <a href="section1-2.html" class="btn">Next: 1.2 Weak Supervision &rarr;</a>
        </div>

    </main>
</body>
</html>
